{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Copia de part_chairs_RESNET_2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leomaestri/DeepLearning_VAE-GANs_Project/blob/master/part_chairs_RESNET_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVR5Ty1f_Z06",
        "colab_type": "text"
      },
      "source": [
        "### Library Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "f0Po-4QlfGJX",
        "colab": {}
      },
      "source": [
        "# Link de origen de datos: https://vcc.tech/research/2018/G2L\n",
        "# Loading libraries \n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "from mpl_toolkits import mplot3d\n",
        "\n",
        "import glob\n",
        "import sys\n",
        "import os\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.utils.data as dts\n",
        "import torch.nn as nn\n",
        "import torch.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "from skimage import io, transform\n",
        "import scipy.io as sio\n",
        "import time\n",
        "\n",
        "import random\n",
        "from IPython.display import display, clear_output"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZFmKcZ5psFc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2c40469e-83e0-4c3f-f3a1-fe9c0fdfa8af"
      },
      "source": [
        "torch.autograd.set_detect_anomaly(True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x7f885c50a630>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6zfwI27A16Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Funciones para alterar en el codigo que repite mucha logica\n",
        "def aTensor(chair):\n",
        "    return torch.Tensor(chair)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElVMn-5jtCyC",
        "colab_type": "text"
      },
      "source": [
        "## Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SCpxBciqbfwW",
        "colab": {}
      },
      "source": [
        "# # Permito el acceso de colab a mi drive\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gGqAeeOLZvWv",
        "colab": {}
      },
      "source": [
        "# Copio de mi drive a la notebook el dataset de sillas\n",
        "#!cp -r \"drive/My Drive/data/chair\" /content/chair\n",
        "\n",
        "# Creo la carpeta modelos (hacer un if por si ya esta creada)\n",
        "#!mkdir modelos"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0OCmoW-1Az3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git config --global user.email 'leo.maestri.g@gmail.com'\n",
        "!git config --global user.name 'leomaestri'\n",
        "password = \"1milanesas\""
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xggm21fm8mnX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "245bcacd-dd1f-4d24-ee64-3ce62835dfdf"
      },
      "source": [
        "!git clone https://leomaestri:$password@github.com/leomaestri/DeepLearning_VAE-GANs_Project.git"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'DeepLearning_VAE-GANs_Project'...\n",
            "remote: Enumerating objects: 40, done.\u001b[K\n",
            "remote: Counting objects: 100% (40/40), done.\u001b[K\n",
            "remote: Compressing objects: 100% (39/39), done.\u001b[K\n",
            "remote: Total 1002 (delta 1), reused 3 (delta 0), pack-reused 962\u001b[K\n",
            "Receiving objects: 100% (1002/1002), 3.25 MiB | 6.06 MiB/s, done.\n",
            "Resolving deltas: 100% (11/11), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82yH-bFr8P2q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "time.sleep(15)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-60lo2JFwJtZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Copio de mi repo a la notebook el dataset de sillas\n",
        "!cp -r \"DeepLearning_VAE-GANs_Project/Dataset/chair\" /content/chair\n",
        "\n",
        "# Creo la carpeta modelos (hacer un if por si ya esta creada)\n",
        "!mkdir modelos"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CgSFuR6SrMGd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_mat(matFile, cube_len):\n",
        "    data = sio.loadmat(matFile)\n",
        "    volume_size = (cube_len, cube_len, cube_len)\n",
        "    array = np.ndarray(volume_size, np.int32)\n",
        "    array = data['instance']\n",
        "    return array"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SuobgK5p7Q8P",
        "colab": {}
      },
      "source": [
        "# Dataset a para cargarle las sillas\n",
        "class DirChairDataset(torch.utils.data.Dataset):\n",
        "    \"\"\"\n",
        "    Dataset de sillas 3D desde directorio\n",
        "    \"\"\"\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.transform = transform\n",
        "        assert os.path.exists(root_dir)\n",
        "        self.root_dir = root_dir\n",
        "        self.archivos = os.listdir(self.root_dir)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.archivos)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        matriz = load_mat(os.path.join(self.root_dir, self.archivos[idx]), 32)\n",
        "        sample = matriz[np.newaxis, ...] # Le agrego un canal\n",
        "        if self.transform:\n",
        "            sample = self.transform(sample)\n",
        "        return sample\n",
        "    \n",
        "    def load_mat(matFile, cube_len):\n",
        "        data = sio.loadmat(matFile)\n",
        "        volume_size = (cube_len, cube_len, cube_len)\n",
        "        array = np.ndarray(volume_size, np.int32)\n",
        "        array = data['instance'] # No se pueden combinar estas 2 celdas, o 3 con el return\n",
        "        return array\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMRZSnqFhct8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def normalizar(y, valorComparacion):\n",
        "   mask = y > valorComparacion\n",
        "   y[mask] = 1\n",
        "   y[~mask] = 0\n",
        "   return y\n",
        "\n",
        "def girar_grafico_3D_frente(grafico):\n",
        "  grafico.view_init(-55, 35) # eje x, eje z   (-55, 35)frente\n",
        "  plt.draw()\n",
        "  return grafico\n",
        "\n",
        "def mostrar_voxel_normalizado_frente(*args):\n",
        "  for x in args:\n",
        "    fig = plt.figure(figsize=(20, 10))\n",
        "    axes = fig.gca(projection='3d')\n",
        "    axes.voxels(x, facecolors='y', edgecolors='k')\n",
        "    axes = girar_grafico_3D_frente(axes)\n",
        "    plt.show()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfLDte-G3poc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_path = 'chair/train/'"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TT9vWfhf56SC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "chair_files = os.listdir(data_path)\n",
        "prueba = DirChairDataset.load_mat(data_path + chair_files[0], 64)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMw-rmpd9sda",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        },
        "outputId": "a09d7a75-3323-4101-8d8f-1839549bc1bb"
      },
      "source": [
        "# Pruebo levantando una matriz como ejemplo.\n",
        "# Las partes tienen asignados distintos numeros, del 1 al 4\n",
        "\n",
        "fig = plt.figure(figsize=(10, 5))\n",
        "axes = fig.gca(projection='3d')\n",
        "axes.voxels(prueba, facecolors='y', edgecolors='k')\n",
        "axes.view_init(-55, 0)\n",
        "plt.draw()\n",
        "plt.pause(.001)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Et6qsyu878G6",
        "colab": {}
      },
      "source": [
        "# Semilla\n",
        "seed = 1234\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "# Intersection over union (IoU) \n",
        "# Es una metrica que me dice que tan bien se detecto un objeto. Lleva ese nombre\n",
        "# porque se refiere a la 'interseccin' entre el area detectada real y la prediccion area detectada,\n",
        "# 'over' de 'sobre' como una fraccion y 'union' entre el area detectada real y \n",
        "# la prediccion area detectada. Me dice cuanto de el area real se detecto.\n",
        "\n",
        "def iou(pred, target):\n",
        "  intersection = torch.Tensor(pred * target).long().sum()\n",
        "  union = torch.Tensor(pred + target).long().sum() - intersection\n",
        "  # intersection = (pred_inds[target_inds]).long().sum().data.cpu()[0]  # Cast to long to prevent overflows\n",
        "  # union = pred_inds.long().sum().data.cpu()[0] + target_inds.long().sum().data.cpu()[0] - intersection\n",
        "\n",
        "  iou = None\n",
        "  if union == 0:\n",
        "    iou = 'nan'  # If there is no ground truth, do not include in evaluation\n",
        "  else:\n",
        "    iou = float(intersection) / float(max(union, 1))\n",
        "  return iou"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqNPS4rANqR5",
        "colab_type": "text"
      },
      "source": [
        "## Data Augmentation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVgMen5Sk3Cf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "7721c65e-4a5d-4783-d9c6-51ae1d89e186"
      },
      "source": [
        "# Creo una lista usando una seed para que sea siempre la misma\n",
        "# Esta lista contiene una proporcion igualitaria de 1,2,3,4 para elegir las partes individuales\n",
        "# El restante de la division lo uso en la parte 3 de brazos\n",
        "\n",
        "largoDataset = len(dataset.archivos)\n",
        "sobrantes = largoDataset % 4\n",
        "cantidadProporcional = int((largoDataset - sobrantes) / 4)\n",
        "\n",
        "listaEquilibrada = [1] * cantidadProporcional + [2] * cantidadProporcional + [3] * (cantidadProporcional + sobrantes) + [4] * cantidadProporcional\n",
        "\n",
        "random.seed(1234)\n",
        "random.shuffle(listaEquilibrada)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-5935b2d79377>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# El restante de la division lo uso en la parte 3 de brazos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mlargoDataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marchivos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0msobrantes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlargoDataset\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mcantidadProporcional\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlargoDataset\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0msobrantes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'dataset' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-fdb6BbpnLy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Defino el dispositivo GPU para usar\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCM3H0pUq4Tl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creo una funcion que devuelve un dataloader con los datos agregados de partes\n",
        "# individuales ademas de las sillas completas\n",
        "\n",
        "def dataAugmentedDataloader():\n",
        "  seed = 123\n",
        "  individual_random_parts = []\n",
        "  batch_size=1\n",
        "\n",
        "  trf_composed = transforms.Compose([aTensor])  \n",
        "  data_path = 'chair/train/'\n",
        "\n",
        "  dataset = DirChairDataset(data_path, transform=trf_composed)  \n",
        "\n",
        "  for i, chair in enumerate(dataset):\n",
        "    randomPart = listaEquilibrada[i]\n",
        "    \n",
        "    # Separo partes individuales de cada silla de manera aleatoria\n",
        "    chairWithoutPart = [(dataset[i] == randomPart).float().to(device)]\n",
        "    individual_random_parts.append(chairWithoutPart[0])\n",
        "\n",
        "  # Junto los datasets de sillas completas con el de partes individuales random\n",
        "  chairs_and_parts = dts.ConcatDataset( [dataset,individual_random_parts] )\n",
        "  data_loader = torch.utils.data.DataLoader(dataset=chairs_and_parts, batch_size=batch_size,\n",
        "                                            shuffle=True, drop_last=True)\n",
        "  return data_loader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UbxSCnz0ODxI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#ESTO LO USE PARA VER QUE SE ESTEN CREANDO BIEN LAS PARTES INDIVIDUALES Y JUNTANDO CON LAS SILLAS\n",
        "# !rm -rf results\n",
        "# !mkdir results\n",
        "\n",
        "# iterator = iter(dataAugmentedDataloader())\n",
        "\n",
        "# for numeroDeImagen in range(10):\n",
        "#   x = iterator.next()\n",
        "#   x_orig = x\n",
        "\n",
        "#   x_real = x_orig[0, 0, ...]\n",
        "#   x = x_orig\n",
        "\n",
        "#   x_real = normalizar(x_real, 0)\n",
        "\n",
        "#   rutaGuardadoReal = f\"results/{numeroDeImagen}_real\"\n",
        "  \n",
        "#   fig = plt.figure(figsize=(20, 10))\n",
        "#   axes = fig.gca(projection='3d')\n",
        "#   axes.voxels(x_real, facecolors='y', edgecolors='k')\n",
        "#   axes = girar_grafico_3D_frente(axes)\n",
        "#   plt.savefig(rutaGuardadoReal, format='png')\n",
        "#   fig.clear()\n",
        "#   plt.close(fig)\n",
        "\n",
        "# # Mando las imagenes al drive\n",
        "# !cp -r results/ \"drive/My Drive/sillas/Crear_Partes_Solas/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tpvkRFZMnWMt"
      },
      "source": [
        "# **Neural Network - ResNet VAE**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5e4RSPb4lMs",
        "colab_type": "text"
      },
      "source": [
        "### Convolutions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmhikDkN4Gly",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def conv3x3x3(in_planes, out_planes, stride=1, groups=1, padding=0):\n",
        "    \"\"\"3x3 convolution with padding\"\"\"\n",
        "    return nn.Conv3d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                     padding=padding, groups=groups, bias=False)\n",
        "\n",
        "def conv4x4x4(in_planes, out_planes, stride=1, groups=1, padding=0):\n",
        "    \"\"\"4x4 convolution with padding\"\"\"\n",
        "    return nn.Conv3d(in_planes, out_planes, kernel_size=4, stride=stride,\n",
        "                     padding=padding, groups=groups, bias=False)\n",
        "    \n",
        "def conv1x1x1(in_planes, out_planes, stride=1):\n",
        "    \"\"\"1x1 convolution\"\"\"\n",
        "    return nn.Conv3d(in_planes, out_planes, kernel_size=1, stride=stride,\n",
        "                     bias=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOibMw3UD5c4",
        "colab_type": "text"
      },
      "source": [
        "## Deconvolutions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hc64dxW8EHJJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Las Traspuestas son las deconvoluciones\n",
        "def t_conv3x3x3(in_planes, out_planes, stride=1, groups=1, padding=0):\n",
        "    \"\"\"3x3 convolution with padding\"\"\"\n",
        "    return nn.ConvTranspose3d(in_planes, out_planes, kernel_size=3,\n",
        "                              stride=stride, padding=padding, groups=groups,\n",
        "                              bias=False)\n",
        "\n",
        "def t_conv4x4x4(in_planes, out_planes, stride=1, groups=1, padding=0):\n",
        "    \"\"\"4x4 convolution with padding\"\"\"\n",
        "    return nn.ConvTranspose3d(in_planes, out_planes, kernel_size=4,\n",
        "                              stride=stride, padding=padding, groups=groups,\n",
        "                              bias=False)\n",
        "    \n",
        "def t_conv2x2x2(in_planes, out_planes, stride=1, groups=1, padding=0):\n",
        "    \"\"\"2x2 convolution with padding\"\"\"\n",
        "    return nn.ConvTranspose3d(in_planes, out_planes, kernel_size=2 ,\n",
        "                              stride=stride, padding=padding, groups=groups,\n",
        "                              bias=False)\n",
        "    \n",
        "def t_conv1x1x1(in_planes, out_planes, stride=1):\n",
        "    \"\"\"1x1 convolution\"\"\"\n",
        "    return nn.ConvTranspose3d(in_planes, out_planes, kernel_size=1,\n",
        "                              stride=stride, bias=False)   \n",
        "        \n",
        "def t_conv2x2x2(in_planes, out_planes, stride=1):\n",
        "    \"\"\"2x2 convolution\"\"\"\n",
        "    return nn.ConvTranspose3d(in_planes, out_planes, kernel_size=2,\n",
        "                              stride=stride, bias=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OOx7w6nx8r0-",
        "colab_type": "text"
      },
      "source": [
        "## Convolution Blocks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nuXdkPVL85uD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Bloque de convolucion 1\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
        "                 base_width=64, norm_layer=None):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm3d\n",
        "        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n",
        "        self.conv1 = conv3x3x3(inplanes, planes, stride=stride, padding=1)\n",
        "        self.bn1 = norm_layer(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3x3(planes, planes, stride=1, padding=1)\n",
        "        self.bn2 = norm_layer(planes)\n",
        "        self.downsample = downsample     #???\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "# Bloque de convolucion 2\n",
        "class BasicBlock2(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
        "                 base_width=64, norm_layer=None):\n",
        "        super(BasicBlock2, self).__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm3d\n",
        "        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n",
        "        self.conv1 = conv4x4x4(inplanes, planes, stride=stride, padding=1)\n",
        "        self.bn1 = norm_layer(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        # La siguiente convolucin no modifica la dimensionalidad de lo que sale\n",
        "        # de la conv1.\n",
        "        self.conv2 = conv3x3x3(planes, planes, stride=1, padding=1)\n",
        "        self.bn2 = norm_layer(planes)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "# Bloque de deconvolucion 1\n",
        "class BasicBlock_dec(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, upsample=None, groups=1,\n",
        "                 base_width=64, norm_layer=None, padding=1):\n",
        "        super(BasicBlock_dec, self).__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm3d\n",
        "        self.conv1 = t_conv3x3x3(inplanes, planes, stride=stride,\n",
        "                                 padding=padding)\n",
        "        self.bn1 = norm_layer(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = t_conv3x3x3(planes, planes, stride=1, padding=padding)\n",
        "        self.bn2 = norm_layer(planes)\n",
        "        self.upsample = upsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.upsample is not None:\n",
        "            identity = self.upsample(x)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "# Bloque de deconvolucion 2\n",
        "class BasicBlock_dec2(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, upsample=None, groups=1,\n",
        "                 base_width=64, norm_layer=None, padding=1):\n",
        "        super(BasicBlock_dec2, self).__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm3d\n",
        "        self.conv1 = t_conv4x4x4(inplanes, planes, stride=stride,\n",
        "                                 padding=padding)\n",
        "        self.bn1 = norm_layer(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = t_conv3x3x3(planes, planes, stride=1, padding=padding)\n",
        "        self.bn2 = norm_layer(planes)\n",
        "        self.upsample = upsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.upsample is not None:\n",
        "            identity = self.upsample(x)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMnof23Q9EG4",
        "colab_type": "text"
      },
      "source": [
        "## Bottleneck"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_cBUWOi9MCh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
        "                 base_width=64, dilation=1, norm_layer=None):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm3d\n",
        "        width = int(planes * (base_width / 64.)) * groups\n",
        "        # Both self.conv2 and self.downsample layers downsample the input when stride != 1\n",
        "        self.conv1 = conv1x1x1(inplanes, width)\n",
        "        self.bn1 = norm_layer(width)\n",
        "        self.conv2 = conv3x3x3(width, width, stride, groups, dilation)\n",
        "        self.bn2 = norm_layer(width)\n",
        "        self.conv3 = conv1x1x1(width, planes * self.expansion)\n",
        "        self.bn3 = norm_layer(planes * self.expansion)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIBPbUJz-mGe",
        "colab_type": "text"
      },
      "source": [
        "## Residual Net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vlqiUEBVBG2M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Encoder\n",
        "\n",
        "class ResNet2(nn.Module):\n",
        "    def __init__(self, block, layers, z_dim=100, zero_init_residual=False,\n",
        "                 groups=1, width_per_group=64,\n",
        "                 norm_layer=None):\n",
        "        super(ResNet2, self).__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm3d\n",
        "        self._norm_layer = norm_layer\n",
        "\n",
        "        self.inplanes = 64\n",
        "        self.groups = groups\n",
        "        self.base_width = width_per_group\n",
        "        self.conv1 = nn.Conv3d(1, self.inplanes, kernel_size=4, stride=4)\n",
        "        self.bn1 = norm_layer(self.inplanes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        # Elimino el maxpool respecto a \"ResNet\"\n",
        "        self.layer1 = self._make_layer(block, 128, layers[0], stride=2)\n",
        "        self.layer2 = self._make_layer(block, 256, layers[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 512, layers[2], stride=2)\n",
        "        self.fc1 = nn.Linear(512, z_dim)\n",
        "        self.fc2 = nn.Linear(512, z_dim)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv3d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            elif isinstance(m, (nn.BatchNorm3d, nn.GroupNorm)):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "        # Zero-initialize the last BN in each residual branch,\n",
        "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
        "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
        "        if zero_init_residual:\n",
        "            for m in self.modules():\n",
        "                if isinstance(m, Bottleneck):\n",
        "                    nn.init.constant_(m.bn3.weight, 0)\n",
        "                elif isinstance(m, BasicBlock):\n",
        "                    nn.init.constant_(m.bn2.weight, 0)\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1):\n",
        "        norm_layer = self._norm_layer\n",
        "        downsample = None\n",
        "        if stride != 1 or self.inplanes != planes:\n",
        "            downsample = nn.Sequential(\n",
        "                conv1x1x1(self.inplanes, planes, stride=stride),\n",
        "                norm_layer(planes)\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\n",
        "                            self.base_width, norm_layer))\n",
        "        self.inplanes = planes\n",
        "        for _ in range(1, blocks):\n",
        "            layers.append(BasicBlock(self.inplanes, planes, groups=self.groups,\n",
        "                                base_width=self.base_width,\n",
        "                                norm_layer=norm_layer))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def reparameterize(self, mu, log_var):\n",
        "        \"\"\" Reparameterizing trick done by the VAE \"\"\"\n",
        "        std = torch.exp(log_var*0.5)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps * std\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        \n",
        "        x = torch.flatten(x, 1)\n",
        "        mu = self.fc1(x)\n",
        "        logvar = self.fc2(x)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "\n",
        "        return mu, logvar, z\n",
        "\n",
        "\n",
        "# Decoder\n",
        "\n",
        "class ResNet_dec2(nn.Module):\n",
        "    def __init__(self, block, layers, z_dim=100, zero_init_residual=False,\n",
        "                 groups=1, width_per_group=64,\n",
        "                 norm_layer=None):\n",
        "        super(ResNet_dec2, self).__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm3d\n",
        "        self._norm_layer = norm_layer\n",
        "\n",
        "        self.inplanes = 512\n",
        "        self.groups = groups\n",
        "        self.base_width = width_per_group\n",
        "        self.bn1 = norm_layer(self.inplanes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        self.layer1 = self._make_layer(block, 256, layers[0], stride=2)\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 64, layers[2], stride=2)\n",
        "        self.conv1 = nn.ConvTranspose3d(64, 1, kernel_size=4, stride=4)\n",
        "        # Elimino el maxpool\n",
        "        self.fc = nn.Linear(z_dim, 512)\n",
        "        self.sigm = nn.Sigmoid()\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.ConvTranspose3d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out',\n",
        "                                        nonlinearity='relu')\n",
        "            elif isinstance(m, (nn.BatchNorm3d, nn.GroupNorm)):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "        # Zero-initialize the last BN in each residual branch,\n",
        "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
        "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
        "        if zero_init_residual:\n",
        "            for m in self.modules():\n",
        "                if isinstance(m, Bottleneck):\n",
        "                    nn.init.constant_(m.bn3.weight, 0)\n",
        "                elif isinstance(m, BasicBlock):\n",
        "                    nn.init.constant_(m.bn2.weight, 0)\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1):\n",
        "        norm_layer = self._norm_layer\n",
        "        upsample = None\n",
        "        if stride != 1 or self.inplanes != planes:\n",
        "            upsample = nn.Sequential(\n",
        "                t_conv2x2x2(self.inplanes, planes,\n",
        "                            stride=stride),\n",
        "                norm_layer(planes)\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, upsample,\n",
        "                            self.groups, self.base_width, norm_layer))\n",
        "        self.inplanes = planes\n",
        "        for _ in range(1, blocks):\n",
        "            layers.append(BasicBlock_dec(self.inplanes, planes,\n",
        "                                         groups=self.groups,\n",
        "                                         base_width=self.base_width,\n",
        "                                         norm_layer=norm_layer))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.fc(x))\n",
        "        x = x.view(-1, 512, 1, 1, 1)\n",
        "\n",
        "        x = self.bn1(x) # Entiendo que no debera servir, porque viene 1x1x1\n",
        "        x = self.relu(x)\n",
        "        \n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        \n",
        "        x = self.conv1(x)\n",
        "        return self.sigm(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NAih-DK0BTL0",
        "colab_type": "text"
      },
      "source": [
        "## Residual Variational Auto Encoder "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sKHJImhznVGt",
        "colab": {}
      },
      "source": [
        "class ResNetVAE2(nn.Module):\n",
        "    def __init__(self, block, layers, z_dim=100, zero_init_residual=False,\n",
        "                 groups=1, width_per_group=64,\n",
        "                 norm_layer=None):\n",
        "        super(ResNetVAE2, self).__init__()\n",
        "        self.encoder = ResNet2(block, layers, z_dim=z_dim) #, **kwargs)\n",
        "        self.decoder = ResNet_dec2(BasicBlock_dec2, layers, z_dim=z_dim*4) #, **kwargs) # modificado para tener en cuenta las 4 partes del VAE\n",
        "    \n",
        "    def forward(self, x):\n",
        "        mu, logvar, z = self.encoder(x)\n",
        "        x_reconst = self.decoder(z)\n",
        "        # x_reconst = self.decoder(mu) # Modificado para hacerlo como autoencoder.\n",
        "        return x_reconst , mu, logvar, z\n",
        "\n",
        "def _resnet_VAE2(arch, block, z_dim, layers, progress, **kwargs):\n",
        "    model = ResNetVAE2(block, layers, z_dim=z_dim)\n",
        "    return model  \n",
        "\n",
        "def resnet18VAE2(z_dim=100, pretrained=False, progress=True, **kwargs):\n",
        "    return _resnet_VAE2('resnet18', BasicBlock2, z_dim, [2, 2, 2, 2],\n",
        "                        progress=progress)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5A8onC9BZZ_x",
        "colab_type": "text"
      },
      "source": [
        "# GANs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxI-WNgfeOJL",
        "colab_type": "text"
      },
      "source": [
        "### Discriminator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bo3_jL3VeM08",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Conv3d(in_channels = 1, out_channels = 64, kernel_size = 4, stride = 2, padding = 1),#, kernel_initializer='he_uniform'),\n",
        "            nn.BatchNorm3d(64),\n",
        "            nn.LeakyReLU(negative_slope = 0.2),\n",
        "            nn.Dropout(0.2), #0.3 #0.4\n",
        "            \n",
        "            nn.Conv3d(in_channels = 64, out_channels = 128, kernel_size = 4, stride = 2, padding = 1),#, kernel_initializer='he_uniform'),,\n",
        "            nn.BatchNorm3d(128),\n",
        "            nn.LeakyReLU(negative_slope = 0.2),\n",
        "            nn.Dropout(0.2), #0.3 #0.4\n",
        "            \n",
        "            nn.Conv3d(in_channels = 128, out_channels = 256, kernel_size = 4, stride = 2, padding = 1),#, kernel_initializer='he_uniform'),\n",
        "            nn.BatchNorm3d(256),\n",
        "            nn.LeakyReLU(negative_slope = 0.2),\n",
        "            nn.Dropout(0.5), #0.4 #0.3\n",
        "            \n",
        "            nn.Conv3d(in_channels = 256, out_channels = 1, kernel_size = 4, stride = 1),# , kernel_initializer='he_uniform'),\n",
        "            nn.Sigmoid()\n",
        "            # Como genero los logit scores? serian 2 en este caso? (real y falso)\n",
        "            #nn.LeakyReLU(negative_slope=0.2),\n",
        "            #nn.Softmax(dim=-1)\n",
        "        )\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv3d):\n",
        "                #nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='leaky_relu')\n",
        "                \n",
        "                #m.weight = nn.init.kaiming_normal_(m.weight, mode='fan_out')\n",
        "                #if m.bias is not None: m.bias.data.zero_()\n",
        "                \n",
        "                #nn.init.kaiming_uniform(m.weight.data, mode='fan_out')\n",
        "                \n",
        "                #nn.init.kaiming_normal_(m.weight, mode='fan_out') \n",
        "                #nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu') \n",
        "                nn.init.xavier_normal(m.weight, gain=np.sqrt(2)) \n",
        "                #nn.init.xavier_normal(m.weight) # NO PROBADO\n",
        "                #nn.init.xavier_uniform(m.weight) # NO PROBADO\n",
        "        self.cuda()\n",
        "\n",
        "    def forward(self, x):\n",
        "        if (len(x.shape) < 5):\n",
        "            x = x.unsqueeze(dim = 1) # add dimension for channels\n",
        "            \n",
        "        return self.layers(x).squeeze()\n",
        "\n",
        "    def clip_weights(self, value):\n",
        "        for parameter in self.parameters():\n",
        "            parameter.data.clamp_(-value, value)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fEjkSgdmoY-P",
        "colab_type": "text"
      },
      "source": [
        "#### Dis Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-Nh9xrLpH01",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from tqdm import tqdm # Para mostrar las barras de progreso\n",
        "\n",
        "# Variables\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "learning_rate = 1e-3    #Default\n",
        "learning_rate_D = 1e-3  #Default\n",
        "num_epochs = 30\n",
        "batch_size = 4\n",
        "\n",
        "trf_composed = transforms.Compose([aTensor])  \n",
        "data_path = 'chair/train/'\n",
        "\n",
        "dataset = DirChairDataset(data_path, transform=trf_composed)  \n",
        "data_loader = torch.utils.data.DataLoader(dataset=dataset, batch_size=batch_size,\n",
        "                                          shuffle=True, drop_last=True)\n",
        "\n",
        "y_real_default = torch.ones(batch_size, requires_grad=False).to(device)\n",
        "y_falso_default = torch.zeros(batch_size, requires_grad=False).to(device)\n",
        "\n",
        "discriminator = Discriminator().to(device)\n",
        "\n",
        "optimizerD = torch.optim.Adam(discriminator.parameters(), lr=learning_rate_D, betas=(0.5, 0.999))\n",
        "\n",
        "def Dis_train(data):\n",
        "\n",
        "    # train discriminator on real samples\n",
        "    x_real = data.to(device)\n",
        "    y_real = torch.ones(batch_size, requires_grad=False).to(device)\n",
        "    y_falso = torch.zeros(batch_size, requires_grad=False).to(device) \n",
        "\n",
        "    optimizerD.zero_grad()\n",
        "    discriminator_output = discriminator(x_real)\n",
        "    D_real_loss = criterion(discriminator_output, y_real)\n",
        "\n",
        "\n",
        "    # train discriminator on fake samples                \n",
        "    x_falso = G_generate(data, generador, device)\n",
        "    y_falso = y_falso.to(device)\n",
        "\n",
        "    discriminator_output = discriminator(x_falso)\n",
        "    D_fake_loss = criterion(discriminator_output, y_falso)\n",
        "\n",
        "    # train discriminator on fake parts\n",
        "    discriminator_output = discriminator(x_falso)\n",
        "    D_fake_loss = criterion(discriminator_output, y_falso)\n",
        "\n",
        "    D_loss = D_real_loss + D_fake_loss\n",
        "    D_loss.backward()\n",
        "    optimizerD.step()\n",
        "\n",
        "    return  D_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRcvCNbqpiBu",
        "colab_type": "text"
      },
      "source": [
        "### Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYtom6JepwVI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def G_generate(x, model, device):\n",
        "\n",
        "    part1, part2, part3, part4 = [(x == (i + 1)).float().to(device) for i in range(4)]\n",
        "    \n",
        "    _,_,part1_z = model.encoder(part1)\n",
        "    _,_,part2_z = model.encoder(part2)\n",
        "    _,_,part3_z = model.encoder(part3)\n",
        "    _,_,part4_z = model.encoder(part4)\n",
        "    z_total = torch.cat([part1_z, part2_z, part3_z, part4_z], dim=1)\n",
        "\n",
        "    y_reconst = model.decoder(z_total)\n",
        "\n",
        "    return y_reconst"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mp3btQqcrDiO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Reconstruccion(model, device, part_z, bachsize, largo):\n",
        "    placeholder = torch.zeros([bachsize, largo])\n",
        "    placeholder[:, 0:25] = part_z\n",
        "    part_z = placeholder.to(device)\n",
        "    return model.decoder(part_z)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cst1e3hid_1y",
        "colab_type": "text"
      },
      "source": [
        "#### Gen Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6y9EDh3wp1GA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def G_train(x, device, model, optimizer):\n",
        "    # Forward pass\n",
        "    # Separa las partes (tienen 1,2,3,4 dentro del dataset, 0 quiere decir vacio)\n",
        "    part1, part2, part3, part4 = [(x == (i + 1)).float().to(device) for i in range(4)]\n",
        "    \n",
        "    ## ENCODER [me da mu, logvar, z]\n",
        "    part1_mu, part1_log_var, part1_z = model.encoder(part1)\n",
        "    part2_mu, part2_log_var, part2_z = model.encoder(part2)\n",
        "    part3_mu, part3_log_var, part3_z = model.encoder(part3)\n",
        "    part4_mu, part4_log_var, part4_z = model.encoder(part4)\n",
        "    # mu, log_var, z_total = model.encoder(y)\n",
        "\n",
        "    # Silla completa sin discriminar partes\n",
        "    mask_chair = x > 0;    x[mask_chair] = 1;    x[~mask_chair] = 0;    y = x.to(device)\n",
        "\n",
        "    # Concatenado de las partes\n",
        "    z_total = torch.cat([part1_z, part2_z, part3_z, part4_z], dim=1)\n",
        "    mu_total = torch.cat([part1_mu, part2_mu, part3_mu, part4_mu], dim=1)\n",
        "    log_var_total = torch.cat([part1_log_var, part2_log_var, part3_log_var, part4_log_var], dim=1)\n",
        "            \n",
        "    # Hasta ac se arma el cdigo concatenado, ahora armo la reconstruccin con los latent codes por partes paddeados\n",
        "    largo = z_total.shape[1]\n",
        "    \n",
        "    optimizer.zero_grad() # Nose si va aca o justo antes del backward como estaba puesto\n",
        "\n",
        "    y_reconst = model.decoder(z_total)\n",
        "\n",
        "    y_si_fuera_real = torch.ones(batch_size, requires_grad=False).to(device)\n",
        "    discriminator_output = discriminator(y_reconst)\n",
        "    D_real_loss = criterion(discriminator_output, y_si_fuera_real) # AGREGAR LA LOSS DE DISCRIMINADOR A LA DEL GENERADOR VAE LOSS\n",
        "\n",
        "    \n",
        "    ##### Calculo las losses #####\n",
        "    \n",
        "    # De la silla completa\n",
        "    reconst_loss = criterion(y_reconst, y)\n",
        "    \n",
        "    # De cada parte de la silla\n",
        "    reconst_loss1 = criterion( Reconstruccion(model, device, part1_z, batch_size, largo), part1 )\n",
        "    reconst_loss2 = criterion( Reconstruccion(model, device, part2_z, batch_size, largo), part2 )\n",
        "    reconst_loss3 = criterion( Reconstruccion(model, device, part3_z, batch_size, largo), part3 )\n",
        "    reconst_loss4 = criterion( Reconstruccion(model, device, part4_z, batch_size, largo), part4 )\n",
        "    \n",
        "    #L1 Loss\n",
        "    criterionL1 = nn.SmoothL1Loss(reduction=reduction)\n",
        "    reconst_L1 = criterionL1(y_reconst, y)\n",
        "    \n",
        "    # KL Divergence Loss\n",
        "    kl_div = -0.5 * torch.sum(1 + log_var_total - mu_total.pow(2) - log_var_total.exp(), dim=-1)\n",
        "    kl_div = torch.sum(kl_div)\n",
        "\n",
        "    # Loss Total para la optimizacion\n",
        "    loss = mult_bce * reconst_loss + mult_parts * (reconst_loss1 + reconst_loss2 + reconst_loss3 + reconst_loss4) + mult_kldiv * kl_div + 0.1 * reconst_L1 + D_real_loss * 0.4\n",
        "           # + mult_adj * adj)\n",
        "    # 0.1 es el valor de lambda1 que le dan a la reconstruccin por partes del cdigo overcomplete que usan en Yin et al. 2019 (LOGAN)\n",
        "    \n",
        "\n",
        "    #optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    return  y_reconst, loss, kl_div, reconst_L1, reconst_loss, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdOwfQ4orr54",
        "colab_type": "text"
      },
      "source": [
        "# Loss Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Wa5NpbNula6",
        "colab_type": "text"
      },
      "source": [
        "## Calculation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTwqKoZiqifG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Intersection over union (IoU) \n",
        "# Es una metrica que me dice que tan bien se detecto un objeto. Lleva ese nombre\n",
        "# porque se refiere a la 'interseccin' entre el area detectada real y la prediccion area detectada,\n",
        "# 'over' de 'sobre' como una fraccion y 'union' entre el area detectada real y \n",
        "# la prediccion area detectada. Me dice cuanto de el area real se detecto.\n",
        "\n",
        "def iou(pred, target):\n",
        "  intersection = torch.Tensor(pred * target).long().sum()\n",
        "  union = torch.Tensor(pred + target).long().sum() - intersection\n",
        "  # intersection = (pred_inds[target_inds]).long().sum().data.cpu()[0]  # Cast to long to prevent overflows\n",
        "  # union = pred_inds.long().sum().data.cpu()[0] + target_inds.long().sum().data.cpu()[0] - intersection\n",
        "\n",
        "  iou = None\n",
        "  if union == 0:\n",
        "    iou = 'nan'  # If there is no ground truth, do not include in evaluation\n",
        "  else:\n",
        "    iou = float(intersection) / float(max(union, 1))\n",
        "  return iou\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZDiAF3oVcwi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def VAE_loss(y, part1, part2, part3, part4, y_reconst, y1_reconst, y2_reconst, y3_reconst, y4_reconst, log_var_total, mu_total):\n",
        "\n",
        "    criterionL1 = nn.SmoothL1Loss(reduction=reduction)\n",
        "\n",
        "    # Estos 4 los puedo dejar afuera del VAE_Loss, directo de reconstruccion\n",
        "    reconst_loss = criterion(y_reconst, y)\n",
        "    reconst_loss1 = criterion(y1_reconst, part1)\n",
        "    reconst_loss2 = criterion(y2_reconst, part2)\n",
        "    reconst_loss3 = criterion(y3_reconst, part3)\n",
        "    reconst_loss4 = criterion(y4_reconst, part4)\n",
        "\n",
        "    reconst_L1 = criterionL1(y_reconst, y)\n",
        "            \n",
        "    kl_div = -0.5 * torch.sum(1 + log_var_total - mu_total.pow(2) - log_var_total.exp(), dim=-1)\n",
        "    kl_div = torch.sum(kl_div)\n",
        "\n",
        "    # Backprop and optimize\n",
        "    # 0.1 es el valor de lambda1 que le dan a la reconstruccin por partes del cdigo overcomplete que usan en Yin et al. 2019 (LOGAN)\n",
        "    loss = mult_bce * reconst_loss + mult_parts * (reconst_loss1 + reconst_loss2 + reconst_loss3 + reconst_loss4) + mult_kldiv * kl_div + 0.1 * reconst_L1\n",
        "           # + mult_adj * adj)\n",
        "\n",
        "    return loss, kl_div, reconst_L1, reconst_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytWIpHWwurtL",
        "colab_type": "text"
      },
      "source": [
        "## Ploting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qwsop82FJrp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Ploteo_Losses(num_epochs, total_sum, bce_sum, l1_sum, kl_div_sum, iou_sum, total_mean, bce_mean, l1_mean, kl_div_mean, iou_mean):\n",
        "\n",
        "    epochl = np.array([i + 1 for i in range(num_epochs)])\n",
        "    fig = plt.figure(figsize=(20, 10))\n",
        "    ax1, ax2, ax3, ax4, ax5, ax6, ax7, ax8, ax9, ax10 = [fig.add_subplot(2, 5, i+1) for i in range(10)]\n",
        "    \n",
        "     \n",
        "    # Ploteo las sumatorias\n",
        "    # titulos = ['Total Loss (sum)', 'BCE Loss (sum)', 'L1 Loss (sum)', 'KL Divergence (sum)', 'IoU Loss (sum)',\n",
        "    #            'Total Loss (mean)', 'BCE Loss (mean)', 'L1 Loss (mean)', 'KL Divergence (mean)', 'IoU Loss (mean)']\n",
        "    # datos = [total_sum, bce_sum, l1_sum, kl_div_sum, iou_sum, total_mean, bce_mean, l1_mean, kl_div_mean, iou_mean]\n",
        "\n",
        "    # ejes = [fig.add_subplot(2, 5, i+1) for i in range(10)]\n",
        "    # for i, grafico in enumerate(datos):\n",
        "    #     ejes[i].cla()\n",
        "    #     ejes[i].set_xlim(0, num_epochs)\n",
        "    #     ejes[i].set_title(titulos[i])\n",
        "    #     ejes[i].plot(epochl, datos)\n",
        "\n",
        "\n",
        "    ax1.cla(); ax1.set_xlim(0, num_epochs); ax1.set_title('Total Loss (sum)'); ax1.plot(epochl, total_sum)\n",
        "    ax2.cla(); ax2.set_xlim(0, num_epochs); ax2.set_title('BCE Loss (sum)'); ax2.plot(epochl, bce_sum, 'r-')\n",
        "    ax3.cla(); ax3.set_xlim(0, num_epochs); ax3.set_title('L1 Loss (sum)'); ax3.plot(epochl, l1_sum, 'g-')\n",
        "    ax4.cla(); ax4.set_xlim(0, num_epochs); ax4.set_title('KL Divergence (sum)'); ax4.plot(epochl, kl_div_sum, 'k-')\n",
        "    ax5.cla(); ax5.set_xlim(0, num_epochs); ax5.set_title('IoU Loss (sum)'); ax5.plot(epochl, iou_sum)\n",
        "\n",
        "    # Ploteo las medias\n",
        "    ax6.cla(); ax6.set_xlim(0, num_epochs); ax6.set_title('Total Loss (mean)'); ax6.plot(epochl, total_mean)\n",
        "    ax7.cla(); ax7.set_xlim(0, num_epochs); ax7.set_title('BCE Loss (mean)'); ax7.plot(epochl, bce_mean, 'r-')\n",
        "    ax8.cla(); ax8.set_xlim(0, num_epochs); ax8.set_title('L1 Loss (mean)'); ax8.plot(epochl, l1_mean, 'g-')\n",
        "    ax9.cla(); ax9.set_xlim(0, num_epochs); ax9.set_title('KL Divergence (mean)'); ax9.plot(epochl, kl_div_mean, 'k-')\n",
        "    ax10.cla(); ax10.set_xlim(0, num_epochs); ax10.set_title('IoU Loss (mean)'); ax10.plot(epochl, iou_mean)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lYiFR81eBfkN",
        "colab_type": "text"
      },
      "source": [
        "# Training Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YL7ax3ILP4N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Variables del modelo\n",
        "\n",
        "batch_size = 4\n",
        "learning_rate = 1e-3\n",
        "learning_rate_D = 1e-3\n",
        "num_epochs = 5\n",
        "use_dropout = True\n",
        "z_dim = 25\n",
        "\n",
        "reduction ='mean'   # modifica el parametro \"reduction\" de las funciones de prdida\n",
        "mult_parts = 1      # modificador de la funcion de perdida de las partes.\n",
        "mult_adj = 0        # multiplicador de la parte de adyacencia de la loss total.\n",
        "#mult_l1 = 1        # se estaba pasando por parametro pero no lo uso en ningun lado\n",
        "mult_kldiv = 1      # multiplicador de la parte KL-Div de la loss total.\n",
        "mult_bce = 1        # multiplicador de la parte BCE de la loss total.\n",
        "\n",
        "\n",
        "criterion = nn.BCELoss(reduction=reduction)\n",
        "generador = resnet18VAE2(z_dim=z_dim).to(device)\n",
        "\n",
        "def binaria(y):\n",
        "    y = y.to('cpu').numpy()\n",
        "    mask = y > 0.5\n",
        "    y[mask] = 1\n",
        "    y[~mask] = 0\n",
        "    return y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xnb7CLibrHwO",
        "colab": {}
      },
      "source": [
        "def correr_VAE(generador, discriminator, data_name, num_run, useDataAugmentation=False):\n",
        "\n",
        "    # Variables\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    trf_composed = transforms.Compose([aTensor])\n",
        "    data_path = 'chair/train/'\n",
        "\n",
        "    # Genero el dataLoader\n",
        "    if useDataAugmentation:\n",
        "      train_chair_data_loader = dataAugmentedDataloader()\n",
        "    else:      \n",
        "      # Cargo los datos de train\n",
        "      train_chair_data = DirChairDataset(data_path, transform=trf_composed)  \n",
        "      train_chair_data_loader = torch.utils.data.DataLoader(dataset=train_chair_data,\n",
        "                                                          batch_size=batch_size,\n",
        "                                                          shuffle=True,\n",
        "                                                          drop_last=True)\n",
        "    #print(generador)\n",
        "    modelo_total_params = sum(p.numel() for p in generador.parameters())\n",
        "    print(\"Total number of parameters in Generator\", modelo_total_params)\n",
        "\n",
        "    #print(discriminator)\n",
        "    modelo_total_params = sum(p.numel() for p in discriminator.parameters())\n",
        "    print(\"Total number of parameters in Discriminator\", modelo_total_params)\n",
        "\n",
        "    optimizerG = torch.optim.Adam(generador.parameters(), lr=learning_rate, betas=(0.5, 0.999))\n",
        "    optimizerD = torch.optim.Adam(discriminator.parameters(), lr=learning_rate_D, betas=(0.5, 0.999))\n",
        "\n",
        "    ## Variables para el calculo de loss, las inicializo como arrays de nulos\n",
        "    l1_sum, bce_sum, kl_div_sum, total_sum, iou_sum, l1_mean, bce_mean, kl_div_mean, total_mean, iou_mean = [np.full(num_epochs, np.nan) for i in range(10)]\n",
        "\n",
        "    # Start training\n",
        "    generador.train();    discriminator.train()\n",
        "\n",
        "    D_losses_bce = np.full(num_epochs, np.nan);   G_losses_bce = np.full(num_epochs, np.nan)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        \n",
        "        kl_div_losses = bce_losses = l1_losses = total_losses = iou_losses = cantidad_para_mean_loss = 0\n",
        "        D_loss_bce = G_loss_bce = 0\n",
        "\n",
        "        for i, x in enumerate(train_chair_data_loader):\n",
        "            \n",
        "            # Loss discriminador\n",
        "            D_Loss = Dis_train(x)\n",
        "            #D_losses_bce.append(D_Loss.item())\n",
        "            #D_losses_bce[i] = D_Loss\n",
        "            D_loss_bce += D_Loss # Ploteo por Epoca en vez de iteracin\n",
        "\n",
        "            y_reconst, loss, kl_div, reconst_L1, reconst_loss, y = G_train(x, device, generador, optimizerG)\n",
        "            \n",
        "            \n",
        "            with torch.no_grad():\n",
        "\n",
        "                # IoU loss\n",
        "                y = binaria(y)\n",
        "                y_reconst = binaria(y_reconst)\n",
        "\n",
        "                #y = y.to('cpu').numpy(); mask = y > 0.5; y[mask] = 1; y[~mask] = 0\n",
        "                #y_reconst = y_reconst.to('cpu').numpy(); mask = y_reconst > 0.5; y_reconst[mask] = 1; y_reconst[~mask] = 0\n",
        "\n",
        "                iou_salida = iou(y_reconst, y)\n",
        "\n",
        "             ## Voy generando las sumatorias en cada iteracion\n",
        "            #cantidad_para_mean_loss += 1 # Siempre es 25 asi que asumo que es el z_dim\n",
        "            kl_div_losses +=  kl_div\n",
        "            l1_losses += reconst_L1\n",
        "            bce_losses += reconst_loss\n",
        "            total_losses += loss\n",
        "            iou_losses += iou_salida\n",
        "\n",
        "            # BCELoss del generador para plotear en paralelo con el discriminador\n",
        "            #G_losses_bce.append(reconst_loss.item())\n",
        "            #G_losses_bce[i] = reconst_loss\n",
        "            G_loss_bce += reconst_loss # Ploteo por Epoca en vez de iteracin\n",
        "\n",
        "        # Si cantidad_para_mean_loss es siempre igual en todas las epocas fijarlo con un numero (len (datos))\n",
        "        # print (f\"cantidad_para_mean_loss = {cantidad_para_mean_loss}\")\n",
        "\n",
        "        # Guardo la sumatoria de la epoch    \n",
        "        l1_sum[epoch] = l1_losses;              bce_sum[epoch] = bce_losses\n",
        "        kl_div_sum[epoch] = kl_div_losses;      total_sum[epoch] = total_losses\n",
        "        iou_sum[epoch] = iou_losses\n",
        "        \n",
        "        D_losses_bce[epoch] = D_loss_bce\n",
        "        G_losses_bce[epoch] = G_loss_bce\n",
        "\n",
        "        # Guardo las medias de la epoch\n",
        "        l1_mean[epoch] = l1_losses / 25\n",
        "        bce_mean[epoch] = bce_losses / 25\n",
        "        kl_div_mean[epoch] = kl_div_losses / 25\n",
        "        total_mean[epoch] = total_losses / 25\n",
        "        iou_mean[epoch] = iou_losses / 25\n",
        "        media_Dis = D_loss_bce / 25\n",
        "\n",
        "        meanLosses_epoca = f\"Epoch[{epoch+1}/{num_epochs}], Reconst Loss: {round(bce_mean[epoch].item(), 2)}, KL Div: {round(kl_div_mean[epoch].item(), 2)}, L1 Loss: {round(l1_mean[epoch].item(), 2)}, Total Loss: {round(total_mean[epoch].item(), 2)}, BCE_Dis {round(media_Dis.item(), 2)}\"\n",
        "        print(meanLosses_epoca)\n",
        "      \n",
        "    torch.save(generador, 'modelos/part_chair_vaegan_G_run_' + str(num_run) + '_' +\n",
        "                str(device) + '.pth')\n",
        "    \n",
        "    torch.save(discriminator, 'modelos/part_chair_vaegan_D_run_' + str(num_run) + '_' +\n",
        "                str(device) + '.pth')\n",
        "    \n",
        "    # Ploteo de losses\n",
        "    Ploteo_Losses(num_epochs, total_sum, bce_sum, l1_sum, kl_div_sum, iou_sum, total_mean, bce_mean, l1_mean, kl_div_mean, iou_mean)\n",
        "    # Ploteo_Losses(num_epochs, total_sum, bce_sum, l1_sum, kl_div_sum, iou_sum, total_mean, bce_mean, l1_mean, kl_div_mean, iou_mean) # Cuando solo ploteo la Sumatoria \n",
        "\n",
        "    #Ploteo la loss del discriminador\n",
        "    plt.figure(figsize=(10,5))\n",
        "    plt.title(\"Generator and Discriminator BCELoss During Training\")\n",
        "    plt.plot(G_losses_bce, label=\"G\")\n",
        "    plt.plot(D_losses_bce, label=\"D\")\n",
        "    plt.xlabel(\"iterations\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    #Por si se alejan demaciado las curvas las ploteo solas\n",
        "    plt.figure(figsize=(10,5))\n",
        "    plt.title(\"Generator BCELoss During Training\")\n",
        "    plt.plot(G_losses_bce, label=\"G\")\n",
        "    #plt.plot(D_losses_bce, label=\"D\")\n",
        "    plt.xlabel(\"iterations\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "    \n",
        "    plt.figure(figsize=(10,5))\n",
        "    plt.title(\"Discriminator BCELoss During Training\")\n",
        "    #plt.plot(G_losses_bce, label=\"G\")\n",
        "    plt.plot(D_losses_bce, label=\"D\")\n",
        "    plt.xlabel(\"iterations\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ewGgJlD0vZ83"
      },
      "source": [
        "# Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNnM_RPI1SBU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Primero probado con Kaiming He initialization\n",
        "# https://arxiv.org/pdf/1502.01852.pdf\n",
        "\n",
        "# Semilla\n",
        "seed = 1234\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "num_run = 35\n",
        "z_dim = 25\n",
        "num_epochs = 400\n",
        "batch_size=32\n",
        "#bz = 32\n",
        "mult_kldiv=1e-5\n",
        "learning_rate=1e-3\n",
        "learning_rate_D = 6e-4 \n",
        "mult_parts=0.1\n",
        "\n",
        "generador = resnet18VAE2(z_dim=z_dim).to(device)\n",
        "discriminator = Discriminator().to(device)\n",
        "\n",
        "correr_VAE(generador, discriminator, 'chairs_2', num_run, useDataAugmentation=True)\n",
        "\n",
        "# Usando data augmentation con partes individuales\n",
        "# Sigmoid con inicializador nn.init.xavier_normal(m.weight, gain=np.sqrt(2))\n",
        "# Dropout en el discriminador\n",
        "# Le baje la relevancia del loss del discriminador para el generador a 0.4\n",
        "# Usando Batchnorm 3d en el discriminador (las primeras 3 capas)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3nH1MYqHsXt6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Guardar un modelo en el drive\n",
        "\n",
        "#!cp modelos/part_chair_vaegan_G_run_35_cuda.pth \"drive/My Drive/modelos/\" \n",
        "#!cp modelos/part_chair_vaegan_D_run_35_cuda.pth \"drive/My Drive/modelos/\" "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTN1kkrdw2EX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# La primera vez copio la carpeta, la proxima solo copiar el contenido a modelos de github\n",
        "!cp modelos/part_chair_vaegan_G_run_35_cuda.pth /content/DeepLearning_VAE-GANs_Project \n",
        "!cp modelos/part_chair_vaegan_D_run_35_cuda.pth /content/DeepLearning_VAE-GANs_Project \n",
        "\n",
        "!git add /content/DeepLearning_VAE-GANs_Project/part_chair_vaegan_G_run_35_cuda.pth\n",
        "!git add /content/DeepLearning_VAE-GANs_Project/part_chair_vaegan_D_run_35_cuda.pth\n",
        "!git commit -m 'Modelo con data aumentation de partes individuales'\n",
        "!git push -u origin master"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "K2VsNOr3YqZD"
      },
      "source": [
        "# Model Outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AiNRL1PN1H6w",
        "colab_type": "text"
      },
      "source": [
        "## Ploting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ciguteoy1HV8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def normalizar(y, valorComparacion):\n",
        "   mask = y > valorComparacion\n",
        "   y[mask] = 1\n",
        "   y[~mask] = 0\n",
        "   return y\n",
        "\n",
        "def girar_grafico_3D_frente(grafico):\n",
        "  grafico.view_init(-55, 35) # eje x, eje z   (-55, 35)frente\n",
        "  plt.draw()\n",
        "  return grafico\n",
        "\n",
        "def mostrar_voxel_normalizado_frente(*args):\n",
        "  for x in args:\n",
        "    fig = plt.figure(figsize=(20, 10))\n",
        "    axes = fig.gca(projection='3d')\n",
        "    axes.voxels(x, facecolors='y', edgecolors='k')\n",
        "    axes = girar_grafico_3D_frente(axes)\n",
        "    plt.show()\n",
        "\n",
        "def mostrar_voxel_normalizado_atras(*args):\n",
        "  for x in args:\n",
        "    fig = plt.figure(figsize=(20, 10))\n",
        "    axes = fig.gca(projection='3d')\n",
        "    axes.voxels(x, facecolors='y', edgecolors='k')\n",
        "    plt.show()\n",
        "\n",
        "def reconstruccion_para_mostrar(part_z, valorComparacion):\n",
        "    placeholder = torch.zeros([32, largo]); placeholder[:, 0:25] = part_z\n",
        "    part_z = placeholder#.to(device)\n",
        "    part_reconst = modelo.decoder(part_z)\n",
        "    part_reconst = part_reconst.to('cpu').numpy()[0, 0, ...]\n",
        "    part_reconst = normalizar(part_reconst, valorComparacion)\n",
        "    return part_reconst"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15pR8bTi2PrF",
        "colab_type": "text"
      },
      "source": [
        "## Model Loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ElPdegg4XHXo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CPU82hYzGTtn",
        "colab": {}
      },
      "source": [
        "# Reconstrucciones\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "z_dim = 25\n",
        "bz = 1\n",
        "\n",
        "# Traigo un modelo que esta guardado en el drive\n",
        "!cp \"drive/My Drive/modelos/part_chair_vaegan_G_run_28_cuda.pth\" modelos/\n",
        "!cp \"drive/My Drive/modelos/part_chair_vae_run_11_cuda.pth\" modelos/ \n",
        "\n",
        "# Elegimos los modelos a comparar y los guardamos en una variable\n",
        "modeloVAEGAN = 'modelos/part_chair_vaegan_G_run_28_cuda.pth' # Modelo 1\n",
        "modeloVAE = 'modelos/part_chair_vae_run_11_cuda.pth' # Modelo 2\n",
        "\n",
        "\n",
        "trf_composed = transforms.Compose([aTensor])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-tkZQ5Zj3NKN",
        "colab_type": "text"
      },
      "source": [
        "## Input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1JsOKtuXH37",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Defino el dataloader\n",
        "\n",
        "# Que datos uso [Train o Test]\n",
        "data_path = 'chair/train'\n",
        "\n",
        "chair_data = DirChairDataset(data_path, transform=trf_composed)\n",
        "chair_data_loader = torch.utils.data.DataLoader(dataset=chair_data,\n",
        "                                                batch_size=bz,\n",
        "                                                shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pswTk95MNmky",
        "colab_type": "text"
      },
      "source": [
        "## Output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HdxYbOffTYd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# En esta celda comparamos modelo VAE y modelo VEAGANS con las reales\n",
        "# 3 Ciclos para guardar juntas las imagenes [Real - VAE - VEAGANS]\n",
        "\n",
        "def generar_almacenar_n_imagenes_2_modelos(chair_data_loader, num_images,\n",
        "                                           modelVAE=None, modelVAEGAN=None, saveReal=True):\n",
        "  \"\"\"\n",
        "    Genera las imagenes reales si saveReal=True (default) y las de los modelos\n",
        "    VAE y VAEGAN si se los paso por parametros. Almacena las imagenes en el\n",
        "    el directorio results, se sobreescribe cada vez que uso la funcion\n",
        "    \n",
        "    saveReal:     indico si deseo o no guardar la imagen original junto con las\n",
        "                  reconstrucciones\n",
        "    modelVAE:     path al modelo VAE dentro de colab\n",
        "    modelVAEGAN:  path al modelo VAEGANS dentro de colab\n",
        "    driveDirName: nombre del directorio que voy a crear en drive\n",
        "  \"\"\"\n",
        "\n",
        "  # Crear directorio en Google Colab\n",
        "  !rm -rf results\n",
        "  !mkdir results\n",
        "\n",
        "  if saveReal:\n",
        "    # Genero y guardo imagen real\n",
        "    iterator = iter(chair_data_loader)\n",
        "\n",
        "    for numeroDeImagen in range(num_images):\n",
        "      x = iterator.next()\n",
        "      x_orig = x\n",
        "\n",
        "      x_real = x_orig[0, 0, ...]\n",
        "      x = x_orig\n",
        "\n",
        "      x_real = normalizar(x_real, 0)\n",
        "\n",
        "      rutaGuardadoReal = f\"results/{numeroDeImagen}_real\"\n",
        "      \n",
        "      fig = plt.figure(figsize=(20, 10))\n",
        "      axes = fig.gca(projection='3d')\n",
        "      axes.voxels(x_real, facecolors='y', edgecolors='k')\n",
        "      axes = girar_grafico_3D_frente(axes)\n",
        "      plt.savefig(rutaGuardadoReal, format='png')\n",
        "      fig.clear()\n",
        "      plt.close(fig)\n",
        "\n",
        "  if modelVAE is not None:\n",
        "    # Genero y guardo imagen reconstruida de VAE\n",
        "    iterator = iter(chair_data_loader)\n",
        "\n",
        "    model_path = modelVAE\n",
        "    modelo = torch.load(model_path, map_location=lambda storage, loc:storage)\n",
        "    #modelo = modelo.to(device)\n",
        "    modelo.eval()\n",
        "\n",
        "    for numeroDeImagen in range(num_images):\n",
        "      x = iterator.next()\n",
        "      x_orig = x\n",
        "\n",
        "      #x_real = x_orig[0, 0, ...]\n",
        "      x = x_orig\n",
        "\n",
        "      #x_real = normalizar(x_real, 0)\n",
        "\n",
        "      with torch.no_grad():\n",
        "        part1, part2, part3, part4 = [(x == i + 1).float() for i in range(4)]\n",
        "        #part1, part2, part3, part4 = [(x == (i + 1)).float().to(device) for i in range(4)]\n",
        "\n",
        "        _,_, part1_z = modelo.encoder(part1)\n",
        "        _,_, part2_z = modelo.encoder(part2)\n",
        "        _,_, part3_z = modelo.encoder(part3)\n",
        "        _,_, part4_z = modelo.encoder(part4)\n",
        "\n",
        "        z_total = torch.cat([part1_z, part2_z, part3_z, part4_z], dim=1)\n",
        "\n",
        "        x = modelo.decoder(z_total)\n",
        "        #x = x.to('cpu').numpy()[0, 0, ...]\n",
        "        x = x.numpy()[0, 0, ...]\n",
        "\n",
        "        largo = z_total.shape[1]\n",
        "          \n",
        "        #part1_reconst = reconstruccion_para_mostrar(part1_z, 0.5)\n",
        "        #part2_reconst = reconstruccion_para_mostrar(part2_z, 0.5)\n",
        "        #part3_reconst = reconstruccion_para_mostrar(part3_z, 0.5)\n",
        "        #part4_reconst = reconstruccion_para_mostrar(part4_z, 0.5)\n",
        "\n",
        "      # Normalizo entre 0 y 1\n",
        "      x = (x - x.min()) / (x.max() - x.min())\n",
        "      x = normalizar(x, 0.5) \n",
        "\n",
        "      rutaGuardadoReal = f\"results/{numeroDeImagen}_recon_vae\"\n",
        "      \n",
        "      fig2 = plt.figure(figsize=(20, 10))\n",
        "      axes = fig2.gca(projection='3d')\n",
        "      axes.voxels(x, facecolors='y', edgecolors='k')\n",
        "      axes = girar_grafico_3D_frente(axes)\n",
        "      plt.savefig(rutaGuardadoReal, format='png')\n",
        "      fig.clear()\n",
        "      plt.close(fig)\n",
        "\n",
        "  if modelVAEGAN is not None:\n",
        "    # Genero y guardo imagen reconstruida de VAEGANs\n",
        "    iterator = iter(chair_data_loader)\n",
        "\n",
        "    model_path = modelVAEGAN\n",
        "    modelo = torch.load(model_path, map_location=lambda storage, loc:storage)\n",
        "    #modelo = modelo.to(device)\n",
        "    modelo.eval()\n",
        "\n",
        "    for numeroDeImagen in range(num_images):\n",
        "      x = iterator.next()\n",
        "      x_orig = x\n",
        "\n",
        "      #x_real = x_orig[0, 0, ...]\n",
        "      x = x_orig\n",
        "\n",
        "      #x_real = normalizar(x_real, 0)\n",
        "\n",
        "      with torch.no_grad():\n",
        "        part1, part2, part3, part4 = [(x == i + 1).float() for i in range(4)]\n",
        "        #part1, part2, part3, part4 = [(x == (i + 1)).float().to(device) for i in range(4)]\n",
        "\n",
        "        part1_mu, part1_log_var, part1_z = modelo.encoder(part1)\n",
        "        part2_mu, part2_log_var, part2_z = modelo.encoder(part2)\n",
        "        part3_mu, part3_log_var, part3_z = modelo.encoder(part3)\n",
        "        part4_mu, part4_log_var, part4_z = modelo.encoder(part4)\n",
        "\n",
        "        z_total = torch.cat([part1_z, part2_z, part3_z, part4_z], dim=1)\n",
        "        mu_total = torch.cat([part1_mu, part2_mu, part3_mu, part4_mu], dim=1)\n",
        "        log_var_total = torch.cat([part1_log_var, part2_log_var, part3_log_var, part4_log_var], dim=1)\n",
        "\n",
        "        x = modelo.decoder(z_total)\n",
        "        #x = x.to('cpu').numpy()[0, 0, ...]\n",
        "        x = x.numpy()[0, 0, ...]\n",
        "\n",
        "        largo = z_total.shape[1]\n",
        "          \n",
        "        #part1_reconst = reconstruccion_para_mostrar(part1_z, 0.5)\n",
        "        #part2_reconst = reconstruccion_para_mostrar(part2_z, 0.5)\n",
        "        #part3_reconst = reconstruccion_para_mostrar(part3_z, 0.5)\n",
        "        #part4_reconst = reconstruccion_para_mostrar(part4_z, 0.5)\n",
        "\n",
        "      # Normalizo entre 0 y 1\n",
        "      x = (x - x.min()) / (x.max() - x.min())\n",
        "      x = normalizar(x, 0.5) \n",
        "\n",
        "      rutaGuardadoReal = f\"results/{numeroDeImagen}_recon_vaegan\"\n",
        "      \n",
        "      fig2 = plt.figure(figsize=(20, 10))\n",
        "      axes = fig2.gca(projection='3d')\n",
        "      axes.voxels(x, facecolors='y', edgecolors='k')\n",
        "      axes = girar_grafico_3D_frente(axes)\n",
        "      plt.savefig(rutaGuardadoReal, format='png')\n",
        "      fig.clear()\n",
        "      plt.close(fig)\n",
        "\n",
        "  # Mando las imagenes al drive\n",
        "  !cp -r results/ \"drive/My Drive/sillas/2_comparison/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3gD16XJezRU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generar_almacenar_n_imagenes_2_modelos(chair_data_loader, 3, modeloVAE, modeloVAEGAN)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tz0zZGjS2p23",
        "colab_type": "text"
      },
      "source": [
        "### Random Complete Reconstructions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynbyZZG45c5O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "z_dim = 25\n",
        "\n",
        "modelo = resnet18VAE2(z_dim=z_dim)\n",
        "model_path = 'modelos/part_chair_vaegan_G_run_28_cuda.pth'\n",
        "\n",
        "def aTensor(chair):\n",
        "    return torch.Tensor(chair)\n",
        "trf_composed = transforms.Compose([aTensor])\n",
        "\n",
        "modelo = torch.load(model_path, map_location=lambda storage, loc:storage)\n",
        "#modelo = modelo.to(device)\n",
        "modelo.eval()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cC8z1Cgnq5yh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import copy\n",
        "\n",
        "# # Guardo 15 reconstrucciones aleatorias de el modelo\n",
        "# !mkdir reconRandomVaegan\n",
        "# dir = \"reconRandomVaegan\"\n",
        "\n",
        "# # Declaro la fig afuera porque solo voy a usar una y reescribirla muchas veces, para que no se sobrerecargue la RAM\n",
        "# fig = plt.figure(figsize=(20, 10))\n",
        "\n",
        "# for i in range(16):\n",
        "#   # Armo un muestreo de las partes del latent code(100 elementos) para probar qu sale (25 por cada parte de la silla)\n",
        "#   zdim = torch.randn([100])\n",
        "#   z = zdim#.to(device)\n",
        "\n",
        "#   with torch.no_grad():\n",
        "#     reconst = modelo.decoder(z)\n",
        "#     reconst = reconst.numpy()[0, 0, ...]\n",
        "\n",
        "#     # Normalizo, nombro y guardo la imagen completa\n",
        "#     reconst = (reconst - reconst.min()) / (reconst.max() - reconst.min())\n",
        "#     reconst = normalizar(reconst, 0.5)\n",
        "    \n",
        "#     rutaGuardadoRecon = f\"{dir}/{i}_recon_vaegan_real\"\n",
        "\n",
        "#     axes = fig.gca(projection='3d')\n",
        "#     axes.voxels(reconst, facecolors='y', edgecolors='k')\n",
        "#     axes = girar_grafico_3D_frente(axes)\n",
        "#     plt.savefig(rutaGuardadoRecon, format='png')\n",
        "#     fig.clear()\n",
        "#     #plt.close(fig)\n",
        "\n",
        "\n",
        "\n",
        "#     # Sin parte 1\n",
        "#     z1 = copy.deepcopy(z)\n",
        "#     z1[:25] = 0\n",
        "    \n",
        "#     with torch.no_grad():\n",
        "#       reconst = modelo.decoder(z1)\n",
        "#       reconst = reconst.to('cpu').numpy()[0, 0, ...]\n",
        "\n",
        "#     reconst = (reconst - reconst.min()) / (reconst.max() - reconst.min())\n",
        "#     reconst = normalizar(reconst, 0.5)\n",
        "    \n",
        "#     rutaGuardadoRecon = f\"{dir}/{i}_recon_vaegan_sinParte_1\"\n",
        "\n",
        "#     axes = fig.gca(projection='3d')\n",
        "#     axes.voxels(reconst, facecolors='y', edgecolors='k')\n",
        "#     axes = girar_grafico_3D_frente(axes)\n",
        "#     plt.savefig(rutaGuardadoRecon, format='png')\n",
        "#     fig.clear()\n",
        "\n",
        "\n",
        "\n",
        "#     # Sin parte 2\n",
        "#     z2 = copy.deepcopy(z)\n",
        "#     z2[25:50] = 0\n",
        "    \n",
        "#     with torch.no_grad():\n",
        "#       reconst = modelo.decoder(z2)\n",
        "#       reconst = reconst.to('cpu').numpy()[0, 0, ...]\n",
        "    \n",
        "#     reconst = (reconst - reconst.min()) / (reconst.max() - reconst.min())\n",
        "#     reconst = normalizar(reconst, 0.5)\n",
        "    \n",
        "#     rutaGuardadoRecon = f\"{dir}/{i}_recon_vaegan_sinParte_2\"\n",
        "\n",
        "#     axes = fig.gca(projection='3d')\n",
        "#     axes.voxels(reconst, facecolors='y', edgecolors='k')\n",
        "#     axes = girar_grafico_3D_frente(axes)\n",
        "#     plt.savefig(rutaGuardadoRecon, format='png')\n",
        "#     fig.clear()\n",
        "\n",
        "\n",
        "\n",
        "#     # Sin parte 3\n",
        "#     z3 = copy.deepcopy(z)\n",
        "#     z3[50:75] = 0\n",
        "    \n",
        "#     with torch.no_grad():\n",
        "#       reconst = modelo.decoder(z3)\n",
        "#       reconst = reconst.to('cpu').numpy()[0, 0, ...]\n",
        "    \n",
        "#     reconst = (reconst - reconst.min()) / (reconst.max() - reconst.min())\n",
        "#     reconst = normalizar(reconst, 0.5)\n",
        "\n",
        "#     rutaGuardadoRecon = f\"{dir}/{i}_recon_vaegan_sinParte_3\"\n",
        "\n",
        "#     axes = fig.gca(projection='3d')\n",
        "#     axes.voxels(reconst, facecolors='y', edgecolors='k')\n",
        "#     axes = girar_grafico_3D_frente(axes)\n",
        "#     plt.savefig(rutaGuardadoRecon, format='png')\n",
        "#     fig.clear()\n",
        "\n",
        "\n",
        "\n",
        "#     # Sin parte 4\n",
        "#     z4 = copy.deepcopy(z)\n",
        "#     z4[75:100] = 0\n",
        "    \n",
        "#     with torch.no_grad():\n",
        "#       reconst = modelo.decoder(z4)\n",
        "#       reconst = reconst.to('cpu').numpy()[0, 0, ...]\n",
        "\n",
        "#     reconst = (reconst - reconst.min()) / (reconst.max() - reconst.min())\n",
        "#     reconst = normalizar(reconst, 0.5)\n",
        "    \n",
        "#     rutaGuardadoRecon = f\"{dir}/{i}_recon_vaegan_sinParte_4\"\n",
        "\n",
        "#     axes = fig.gca(projection='3d')\n",
        "#     axes.voxels(reconst, facecolors='y', edgecolors='k')\n",
        "#     axes = girar_grafico_3D_frente(axes)\n",
        "#     plt.savefig(rutaGuardadoRecon, format='png')\n",
        "#     fig.clear()\n",
        "\n",
        "# !cp -r reconRandomVaegan/. \"drive/My Drive/sillas/randomRecon/VAEGAN_2\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndEe5KBr3QFt",
        "colab_type": "text"
      },
      "source": [
        "### Random Individual Part Reconstruction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d58yjT0gGI8s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "z_dim = 25\n",
        "\n",
        "modelo = resnet18VAE2(z_dim=z_dim)\n",
        "model_path = 'modelos/part_chair_vaegan_G_run_28_cuda.pth'\n",
        "\n",
        "def aTensor(chair):\n",
        "    return torch.Tensor(chair)\n",
        "trf_composed = transforms.Compose([aTensor])\n",
        "\n",
        "modelo = torch.load(model_path, map_location=lambda storage, loc:storage)\n",
        "#modelo = modelo.to(device)\n",
        "modelo.eval()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0YPfHhJwjVO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import copy\n",
        "# # PARTES: 1 resplado, 2 asiento, 3 patas, 4 brazos\n",
        "\n",
        "# # Guardo 15 reconstrucciones aleatorias de partes del modelo\n",
        "# !rm -rf Recon_random_vaegan_part\n",
        "# !mkdir Recon_random_vaegan_part\n",
        "\n",
        "# # Declaro la fig afuera porque solo voy a usar una y reescribirla muchas veces, para que no se sobrerecargue la RAM\n",
        "# fig = plt.figure(figsize=(20, 10))\n",
        "\n",
        "# for i in range(21):\n",
        "#   # Armo un muestreo de las partes del latent code(100 elementos) para probar qu sale (25 por cada parte de la silla)\n",
        "#   zdim = torch.randn([100])\n",
        "#   z = zdim#.to(device)\n",
        "\n",
        "#   with torch.no_grad():\n",
        "#     reconst = modelo.decoder(z)\n",
        "#     reconst = reconst.numpy()[0, 0, ...]\n",
        "\n",
        "#     # Normalizo, nombro y guardo la imagen completa\n",
        "#     reconst = (reconst - reconst.min()) / (reconst.max() - reconst.min())\n",
        "#     reconst = normalizar(reconst, 0.5)\n",
        "    \n",
        "#     rutaGuardadoRecon = f\"Recon_random_vaegan_part/{i}_recon_vaegan_full\"\n",
        "\n",
        "#     axes = fig.gca(projection='3d')\n",
        "#     axes.voxels(reconst, facecolors='y', edgecolors='k')\n",
        "#     axes = girar_grafico_3D_frente(axes)\n",
        "#     plt.savefig(rutaGuardadoRecon, format='png')\n",
        "#     fig.clear()\n",
        "#     #plt.close(fig)\n",
        "\n",
        "\n",
        "# ##### Solo respaldo #####\n",
        "#     z1 = copy.deepcopy(z)\n",
        "#     z1[25:] = 0\n",
        "\n",
        "#     with torch.no_grad():\n",
        "#       reconst = modelo.decoder(z1)\n",
        "#       reconst = reconst.to('cpu').numpy()[0, 0, ...]\n",
        "\n",
        "#     reconst = (reconst - reconst.min()) / (reconst.max() - reconst.min())\n",
        "#     reconst = normalizar(reconst, 0.5)\n",
        "    \n",
        "#     rutaGuardadoRecon = f\"Recon_random_vaegan_part/{i}_recon_vaegan_parte_1\"\n",
        "\n",
        "#     axes = fig.gca(projection='3d')\n",
        "#     axes.voxels(reconst, facecolors='y', edgecolors='k')\n",
        "#     axes = girar_grafico_3D_frente(axes)\n",
        "#     plt.savefig(rutaGuardadoRecon, format='png')\n",
        "#     fig.clear()\n",
        "\n",
        "# ##### Solo asiento #####\n",
        "#     z2 = copy.deepcopy(z)\n",
        "#     z2[0:25] = 0\n",
        "#     z2[50:] = 0\n",
        "    \n",
        "#     with torch.no_grad():\n",
        "#       reconst = modelo.decoder(z2)\n",
        "#       reconst = reconst.to('cpu').numpy()[0, 0, ...]\n",
        "\n",
        "#     reconst = (reconst - reconst.min()) / (reconst.max() - reconst.min())\n",
        "#     reconst = normalizar(reconst, 0.5)\n",
        "    \n",
        "#     rutaGuardadoRecon = f\"Recon_random_vaegan_part/{i}_recon_vaegan_parte_2\"\n",
        "\n",
        "#     axes = fig.gca(projection='3d')\n",
        "#     axes.voxels(reconst, facecolors='y', edgecolors='k')\n",
        "#     axes = girar_grafico_3D_frente(axes)\n",
        "#     plt.savefig(rutaGuardadoRecon, format='png')\n",
        "#     fig.clear()\n",
        "\n",
        "# ##### Solo patas #####\n",
        "#     z3 = copy.deepcopy(z)\n",
        "#     z3[0:50] = 0\n",
        "#     z3[75:] = 0\n",
        "    \n",
        "#     with torch.no_grad():\n",
        "#       reconst = modelo.decoder(z3)\n",
        "#       reconst = reconst.to('cpu').numpy()[0, 0, ...]\n",
        "\n",
        "#     reconst = (reconst - reconst.min()) / (reconst.max() - reconst.min())\n",
        "#     reconst = normalizar(reconst, 0.5)\n",
        "    \n",
        "#     rutaGuardadoRecon = f\"Recon_random_vaegan_part/{i}_recon_vaegan_parte_3\"\n",
        "\n",
        "#     axes = fig.gca(projection='3d')\n",
        "#     axes.voxels(reconst, facecolors='y', edgecolors='k')\n",
        "#     axes = girar_grafico_3D_frente(axes)\n",
        "#     plt.savefig(rutaGuardadoRecon, format='png')\n",
        "#     fig.clear()\n",
        "\n",
        "# ##### Solo brazos #####\n",
        "#     z4 = copy.deepcopy(z)\n",
        "#     z4[0:75] = 0\n",
        "    \n",
        "#     with torch.no_grad():\n",
        "#       reconst = modelo.decoder(z4)\n",
        "#       reconst = reconst.to('cpu').numpy()[0, 0, ...]\n",
        "\n",
        "#     reconst = (reconst - reconst.min()) / (reconst.max() - reconst.min())\n",
        "#     reconst = normalizar(reconst, 0.5)\n",
        "    \n",
        "#     rutaGuardadoRecon = f\"Recon_random_vaegan_part/{i}_recon_vaegan_parte_4\"\n",
        "\n",
        "#     axes = fig.gca(projection='3d')\n",
        "#     axes.voxels(reconst, facecolors='y', edgecolors='k')\n",
        "#     axes = girar_grafico_3D_frente(axes)\n",
        "#     plt.savefig(rutaGuardadoRecon, format='png')\n",
        "#     fig.clear()\n",
        "\n",
        "# # Guardo las imagenes en una carpeta del drive\n",
        "# !cp -r Recon_random_vaegan_part/. \"drive/My Drive/sillas/Recon_random_vaegan_parts/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "un5vhEISvEWv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !rm -rf results\n",
        "# !mkdir results\n",
        "\n",
        "# num_images = 10\n",
        "# modelVAEGAN = 'modelos/part_chair_vaegan_G_run_28_cuda.pth'\n",
        "\n",
        "# iterator = iter(chair_data_loader)\n",
        "\n",
        "# for numeroDeImagen in range(num_images):\n",
        "#   x = iterator.next()\n",
        "#   x_orig = x\n",
        "\n",
        "#   x_real = x_orig[0, 0, ...]\n",
        "#   x = x_orig\n",
        "\n",
        "#   x_real = normalizar(x_real, 0)\n",
        "\n",
        "#   rutaGuardadoReal = f\"results/{numeroDeImagen}_real\"\n",
        "  \n",
        "#   fig = plt.figure(figsize=(20, 10))\n",
        "#   axes = fig.gca(projection='3d')\n",
        "#   axes.voxels(x_real, facecolors='y', edgecolors='k')\n",
        "#   axes = girar_grafico_3D_frente(axes)\n",
        "#   plt.savefig(rutaGuardadoReal, format='png')\n",
        "#   fig.clear()\n",
        "#   plt.close(fig)\n",
        "\n",
        "\n",
        "\n",
        "# # Genero y guardo imagen reconstruida de VAEGANs\n",
        "# iterator = iter(chair_data_loader)\n",
        "\n",
        "# model_path = modelVAEGAN\n",
        "# modelo = torch.load(model_path, map_location=lambda storage, loc:storage)\n",
        "# #modelo = modelo.to(device)\n",
        "# modelo.eval()\n",
        "\n",
        "# for numeroDeImagen in range(num_images):\n",
        "#   x = iterator.next()\n",
        "#   x_orig = x\n",
        "\n",
        "#   #x_real = x_orig[0, 0, ...]\n",
        "#   x = x_orig\n",
        "\n",
        "#   #x_real = normalizar(x_real, 0)\n",
        "\n",
        "#   with torch.no_grad():\n",
        "#     part1, part2, part3, part4 = [(x == i + 1).float() for i in range(4)]\n",
        "#     #part1, part2, part3, part4 = [(x == (i + 1)).float().to(device) for i in range(4)]\n",
        "\n",
        "#     part1_mu, part1_log_var, part1_z = modelo.encoder(part1)\n",
        "#     part2_mu, part2_log_var, part2_z = modelo.encoder(part2)\n",
        "#     part3_mu, part3_log_var, part3_z = modelo.encoder(part3)\n",
        "#     part4_mu, part4_log_var, part4_z = modelo.encoder(part4)\n",
        "\n",
        "#     z_total = torch.cat([part1_z, part2_z, part3_z, part4_z], dim=1)\n",
        "#     mu_total = torch.cat([part1_mu, part2_mu, part3_mu, part4_mu], dim=1)\n",
        "#     log_var_total = torch.cat([part1_log_var, part2_log_var, part3_log_var, part4_log_var], dim=1)\n",
        "\n",
        "#     x = modelo.decoder(z_total)\n",
        "#     #x = x.to('cpu').numpy()[0, 0, ...]\n",
        "#     x = x.numpy()[0, 0, ...]\n",
        "\n",
        "#     largo = z_total.shape[1]\n",
        "      \n",
        "#     part1_reconst = reconstruccion_para_mostrar(part1_z, 0.5)\n",
        "#     part2_reconst = reconstruccion_para_mostrar(part2_z, 0.5)\n",
        "#     part3_reconst = reconstruccion_para_mostrar(part3_z, 0.5)\n",
        "#     part4_reconst = reconstruccion_para_mostrar(part4_z, 0.5)\n",
        "\n",
        "#   # Normalizo entre 0 y 1\n",
        "#   x = (x - x.min()) / (x.max() - x.min())\n",
        "#   x = normalizar(x, 0.5) \n",
        "\n",
        "#   rutaGuardadoReal = f\"results/{numeroDeImagen}_recon_vaegan\"\n",
        "  \n",
        "#   fig2 = plt.figure(figsize=(20, 10))\n",
        "#   axes = fig2.gca(projection='3d')\n",
        "#   axes.voxels(x, facecolors='y', edgecolors='k')\n",
        "#   axes = girar_grafico_3D_frente(axes)\n",
        "#   plt.savefig(rutaGuardadoReal, format='png')\n",
        "#   fig.clear()\n",
        "#   plt.close(fig)\n",
        "\n",
        "  \n",
        "  \n",
        "#   rutaGuardadoReal = f\"results/{numeroDeImagen}_recon_vaegan_part1\"\n",
        "  \n",
        "#   fig3 = plt.figure(figsize=(20, 10))\n",
        "#   axes = fig3.gca(projection='3d')\n",
        "#   axes.voxels(part1_reconst, facecolors='y', edgecolors='k')\n",
        "#   axes = girar_grafico_3D_frente(axes)\n",
        "#   plt.savefig(rutaGuardadoReal, format='png')\n",
        "#   fig.clear()\n",
        "#   plt.close(fig)\n",
        "\n",
        "#   rutaGuardadoReal = f\"results/{numeroDeImagen}_recon_vaegan_part2\"\n",
        "  \n",
        "#   fig4 = plt.figure(figsize=(20, 10))\n",
        "#   axes = fig4.gca(projection='3d')\n",
        "#   axes.voxels(part2_reconst, facecolors='y', edgecolors='k')\n",
        "#   axes = girar_grafico_3D_frente(axes)\n",
        "#   plt.savefig(rutaGuardadoReal, format='png')\n",
        "#   fig.clear()\n",
        "#   plt.close(fig)\n",
        "\n",
        "#   rutaGuardadoReal = f\"results/{numeroDeImagen}_recon_vaegan_part3\"\n",
        "  \n",
        "#   fig5 = plt.figure(figsize=(20, 10))\n",
        "#   axes = fig5.gca(projection='3d')\n",
        "#   axes.voxels(part3_reconst, facecolors='y', edgecolors='k')\n",
        "#   axes = girar_grafico_3D_frente(axes)\n",
        "#   plt.savefig(rutaGuardadoReal, format='png')\n",
        "#   fig.clear()\n",
        "#   plt.close(fig)\n",
        "\n",
        "#   rutaGuardadoReal = f\"results/{numeroDeImagen}_recon_vaegan_part4\"\n",
        "  \n",
        "#   fig6 = plt.figure(figsize=(20, 10))\n",
        "#   axes = fig6.gca(projection='3d')\n",
        "#   axes.voxels(part4_reconst, facecolors='y', edgecolors='k')\n",
        "#   axes = girar_grafico_3D_frente(axes)\n",
        "#   plt.savefig(rutaGuardadoReal, format='png')\n",
        "#   fig.clear()\n",
        "#   plt.close(fig)\n",
        "  \n",
        "# # Mando las imagenes al drive\n",
        "# !cp -r results/ \"drive/My Drive/sillas/probando_partes_reales/\""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
